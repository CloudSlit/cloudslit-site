[{"id":0,"href":"/cloudslit_docs/cloudslit/cloudslit-client/architecture/overview/","title":"OverView","section":"Architecture","content":" OverView # "},{"id":1,"href":"/cloudslit_docs/cloudslit/cloudslit-contracts/architecture/overview/","title":"OverView","section":"Architecture","content":" OverView # "},{"id":2,"href":"/cloudslit_docs/cloudslit/cloudslit-fullnode/architecture/overview/","title":"OverView","section":"Architecture","content":" OverView # "},{"id":3,"href":"/cloudslit_docs/cloudslit/cloudslit-provider/architecture/overview/","title":"OverView","section":"Architecture","content":" OverView # "},{"id":4,"href":"/cloudslit_docs/cloudslit/cloudslit-verifier/architecture/overview/","title":"OverView","section":"Architecture","content":" OverView # "},{"id":5,"href":"/cloudslit_docs/cloudslit/deca/architecture/overview/","title":"OverView","section":"Architecture","content":" OverView # "},{"id":6,"href":"/cloudslit_docs/cloudslit/cloudslit-client/architecture/network/","title":"NetWork","section":"Architecture","content":" NetWork Details # "},{"id":7,"href":"/cloudslit_docs/cloudslit/cloudslit-fullnode/architecture/network/","title":"NetWork","section":"Architecture","content":" NetWork Details # "},{"id":8,"href":"/cloudslit_docs/cloudslit/cloudslit-provider/architecture/network/","title":"NetWork","section":"Architecture","content":" NetWork Details # "},{"id":9,"href":"/cloudslit_docs/cloudslit/cloudslit-verifier/architecture/network/","title":"NetWork","section":"Architecture","content":" NetWork Details # "},{"id":10,"href":"/cloudslit_docs/cloudslit/deca/architecture/network/","title":"NetWork","section":"Architecture","content":" NetWork Details # "},{"id":11,"href":"/cloudslit_docs/cloudslit/cloudslit-client/architecture/storage/","title":"Storage","section":"Architecture","content":" Storage Engine Details # "},{"id":12,"href":"/cloudslit_docs/cloudslit/cloudslit-contracts/architecture/storage/","title":"Storage","section":"Architecture","content":" Storage Engine Details # "},{"id":13,"href":"/cloudslit_docs/cloudslit/cloudslit-fullnode/architecture/storage/","title":"Storage","section":"Architecture","content":" Storage Engine Details # "},{"id":14,"href":"/cloudslit_docs/cloudslit/cloudslit-provider/architecture/storage/","title":"Storage","section":"Architecture","content":" Storage Engine Details # "},{"id":15,"href":"/cloudslit_docs/cloudslit/cloudslit-verifier/architecture/storage/","title":"Storage","section":"Architecture","content":" Storage Engine Details # "},{"id":16,"href":"/cloudslit_docs/cloudslit/deca/architecture/storage/","title":"Storage","section":"Architecture","content":" Storage Engine Details # "},{"id":17,"href":"/cloudslit_docs/cloudslit/vocabulary/","title":"Vocabulary","section":"Overview","content":" Vocabulary # The main terms used in cloudslit products are listed below.\n"},{"id":18,"href":"/cloudslit_docs/cloudslit/cloudslit-client/architecture/protocol/","title":"Protocol","section":"Architecture","content":" Protocol Details # "},{"id":19,"href":"/cloudslit_docs/cloudslit/cloudslit-contracts/architecture/protocol/","title":"Protocol","section":"Architecture","content":" Protocol Details # "},{"id":20,"href":"/cloudslit_docs/cloudslit/cloudslit-fullnode/architecture/protocol/","title":"Protocol","section":"Architecture","content":" Protocol Details # "},{"id":21,"href":"/cloudslit_docs/cloudslit/cloudslit-provider/architecture/protocol/","title":"Protocol","section":"Architecture","content":" Protocol Details # "},{"id":22,"href":"/cloudslit_docs/cloudslit/cloudslit-verifier/architecture/protocol/","title":"Protocol","section":"Architecture","content":" Protocol Details # "},{"id":23,"href":"/cloudslit_docs/cloudslit/deca/architecture/protocol/","title":"Protocol","section":"Architecture","content":" Protocol Details # "},{"id":24,"href":"/cloudslit_docs/cloudslit/cloudslit-fullnode/quick_start/","title":"Quick Start","section":"CloudSlit-Fullnode","content":" Quick Start # "},{"id":25,"href":"/cloudslit_docs/cloudslit/","title":"Overview","section":"CloudSlit","content":" CloudSlit - Private retrieval of data # inspiration # At present, the options available for interactive (low-latency) communication with privacy guarantee are very limited, and the solutions developed so far all focus on the traditional web model of single source data publisher, and it has defects in delay and threat models.\nCloudSlit uses blockchain, web3 and secure network technology of private data retrieval to enhance and improve network security/privacy protection of users\u0026rsquo; privatization.\nIn order to protect the public\u0026rsquo;s network security under web2, a very popular zero-trust security architecture has emerged. Our team has been working on open source products with zero trust security, but we found that although many zero trust network security companies provide zero trust security platforms, they monopolize users\u0026rsquo; network access nodes and centrally store users\u0026rsquo; core security profiles. Therefore, we are considering whether we can use web3 technology to realize a secure network for private data retrieval. We designed CloudSlit project to provide users with a decentralized secure network platform for private data retrieval, and help users master their own secure data.\nIts value # CloudSlit aims to build a decentralized private data retrieval security network system of web3 in the world, and help users recapture the privacy security information eroded by giants under web2, so that the current global hot zero-trust security network technology combined with web3 can better help users master their own security privacy data and give users a good experience of private data retrieval security network products.\nHow do we build it? # The design part of CloudSlit project includes distributed full-nodes, network miner provider, intelligent contract, network quality checker and network client program. The details are as follows:\nPart Ⅰ: CloudSlit-Fullnode (Ful nodes of private data retrieval network based on DAO Tools) # Anyone can run Fullnode, which hosts the metadata of decentralized network and provides metadata networking and transaction matching platform. It integrates metadata from all providers, and providers use libp2p-based pubsub every few seconds to keep heartbeat to Fullnode to prove that they are online.\nUsers can find resources and nodes to build their own secure anonymous network tunnel. They only need to pay some tokens, and the provider nodes can get these tokens as rewards.\nFor all users\u0026rsquo; and Dao\u0026rsquo;s data, we use Filecoin\u0026rsquo;s web3.storage to store user data in a decentralized way.\nPart Ⅱ: CloudSlit-Provider (Network Miner, a Secure Network Tunnel Provider for Decentralized Data Private Retrieval) # Our nodes are automatically networked through kademlia DHT and IPFS networks of libp2p through peer discovery and routing, and data synchronization among multiple nodes is realized through PubSub function of libp2p.\nFor all users and Dao data, we use web3.storage of Filecoin to store user data in a decentralized way.\nPart Ⅲ: **CloudSlit-Contracts **(./support:EVM Chains) # We provide a complete smart contract for the decentralized trusted bandwidth market. Our smart contract is deployed on the EVM network, and we provide many methods in the smart contract to ensure a safe trading process and a safe trading environment.\nPart Ⅳ: CloudSlit-verifier (Decentralized network quality checker) # We provide the verifier component for the decentralized trusted bandwidth market. Anyone can run the network verifier, monitor the network quality of ongoing orders, and detect and punish illegal and bad network providers.\nPart Ⅴ: DeCA (Decentralized PKI CA center) # Decentralize PKI CA center to provide communication authentication infrastructure for Dao point-to-point communication.\nPart Ⅵ: CloudSlit-Client (client for private data retrieval.) # A client user connects to a provider to establish a network security tunnel for private data retrieval.\nThanks supports # Protocol Labs Filecoin Nervos "},{"id":26,"href":"/cloudslit_docs/cloudslit/cloudslit-fullnode/tutorials/","title":"Tutorials","section":"CloudSlit-Fullnode","content":" Tutorials # "},{"id":27,"href":"/cloudslit_docs/cloudslit/cloudslit-fullnode/deploy/","title":"Deploy","section":"CloudSlit-Fullnode","content":" Deploy # "},{"id":28,"href":"/cloudslit_docs/cloudslit/cloudslit-fullnode/develop/","title":"Develop","section":"CloudSlit-Fullnode","content":" Develop # "},{"id":29,"href":"/cloudslit_docs/cloudslit/qa/","title":"FAQs","section":"Overview","content":" FAQs # 1. Would you be able to write IPLD Schemas and specs for the data structures you\u0026rsquo;re using? This would allow others to implement writers/readers for their data. # Our current database underlying data storage engine implementation is divided into two categories:\nThe first kind: build database synchronization technology based on RESP instructions and SQL statements, which can only grow and cannot be tampered with, and realize data synchronization and consistency guarantee between nodes based on decentralized instruction broadcasting and storage instruction playback. Type two: realize KV storage engine based on IPFS kv, and build rich nosql data structure by coding kv-value, so that the data of database can grow on ipfs completely, instead of relying on ipfs-log function. At present, the first type of database is mainly implemented. We mainly use ipfs-log, an immutable and conflict-free replication data model for distributed systems. Based on ipfs-log, the kv engine is abstracted. Based on this kv engine, it is one of the storage drivers of cloudslit. Other projects can rely on this kv engine to implement their own writers and readers, but we have not designed a proprietary IPLD data structure at present.\ncloudslit abstracts a data coding layer on the kv engine, which can support more complex data structures such as hash\\list besides the basic KV operation. Currently, ipfs kv storage has been realized in the data storage directory of Icefire DB, and we hope that the data of the database can be fully grown on ipfs, but at present, we need to solve the need of kv key synchronization first. The expression of nosql and sql data relationship for ipfs kv is also conceiving the design of ipld, but it is not in the current major construction milestone. ipld is what we have been learning recently,If more complicated IPLD design is involved later, we will practice it in the process of learning.\n2. How does the DB run? # In this milestone, our implementation mode is the server running mode, which needs to run in a server somewhere. Our server will support Redis-RESP protocol and MYSQL communication protocol, and clients can use Golang, JS, PHP and other computer languages to connect.\nThere is also a framework way, which allows users to directly embed into the application code. This integration method is not in the current milestone, and we plan to concentrate on realizing it after this milestone.For example:redhub,cloudslit-crdt-kv,ipfs-nosql-frame.These projects are open sourced by cloudslit and are licensed under the Apache-2.0 open source license, and are mainly used to build ipfs-nosql-frame project, so that other Golang applications can be integrated more conveniently.\nCompared with the framework mode, the server operation mode has the following advantages:\nProvide standard data protocols (RESP, MYSQL), which can make the application minimize changes and use decentralized database. Mask the complexity under IPFS, including libp2p, ipfs-log and crdt. 3. How will you address mutability of data? # We know the immutability of IPFS itself, and now cloudslit has two implementation models to solve the variability of data:\nThe first implementation: instruction broadcast model based on ipfs-log: Based on ipfs-log,crdt and libp2p(pubsub), an immutable and operation-based conflict-free replication data model for distributed systems is implemented. Based on ipfs-log, various data structures such as event and kv are encapsulated, and multi-node database instruction broadcast is implemented based on this engine;At that bottom of cloudslit, we abstract the variable kv engine base on badgerdb and leveldb. any node will broadcast the whole network when it is writing instruction, and the bottom driver of cloudslit of each node will execute the broadcast instruction to ensure the final consistency of data.\nThe second implementation: full storage model based on ipfs: In addition to the first implementation mode, we are also building the structure of the second type of data, so that the complete data will grow on ipfs. At first, there is an ipfs driver in the cloudslit driver layer, which will encode and process the upper-level commands into a unified kv data structure, store and change the value, and the generated new cid will be connected with key. However, at present, there is no key broadcast network with multiple nodes and data synchronization. When we connect with the broadcast network, we can build a data model originally grown on ipfs.\n4. What program languages are you targeting? # Our program implementation is Golang.\nWe provide standard Redis-RESP and MYSQL communication protocols, so Redis and MYSQL clients of other computer programming languages can communicate with cloudslit (JS, Rust)\n"},{"id":30,"href":"/cloudslit_docs/cloudslit/news/","title":"News","section":"Overview","content":" Record the bits and pieces of cloudslit. # "}]